/// Abstractions for Kdeps LLM Resource
///
/// This module provides an abstraction layer for managing resources related to
/// large language model (LLM) interactions within the Kdeps system.
///
/// It defines the [ResourceChat] class, which encapsulates the metadata and responses
/// related to LLM model interactions. The class allows for managing prompts, responses,
/// file generations, image generation flags, and the handling of JSON responses.
///
/// Key functionalities include:
/// - Managing a collection of resources that represent LLM interactions through a mapping of unique
/// resource IDs to [ResourceChat] objects.
/// - Providing methods to retrieve various pieces of information related to the LLM interaction,
/// such as the prompt text, response text, file paths, JSON keys, and whether image generation was
/// involved.
@ModuleInfo { minPklVersion = "0.27.1" }

@go.Package { name = "github.com/kdeps/schema/gen/llm" }

open module org.kdeps.pkl.LLM

extends "Utils.pkl"
import "package://pkg.pkl-lang.org/pkl-go/pkl.golang@0.5.0#/go.pkl"

/// A mapping of resource IDs to their associated [ResourceChat] objects.
resources: Mapping<String, ResourceChat>?

/// Class representing the details of a chat interaction with an LLM model, including prompts, responses,
/// file generation, and additional metadata.
class ResourceChat {
        /// The name of the LLM model used for the chat.
        model: String = "llama3.2"

        /// The prompt text sent to the LLM model.
        prompt: String

        /// A listing of file paths or identifiers associated with the chat.
        files: Listing<String>?

        /// Whether the LLM's response is in JSON format. Defaults to `false`.
        JSONResponse: Boolean? = false

        /// A listing of keys expected in the JSON response from the LLM model.
        JSONResponseKeys: Listing<String>?

        /// The actual response returned from the LLM model.
        response: String?

        /// The file path where the LLM response of this resource is saved
        file: String?

        /// A timestamp of when the response was generated, represented as an unsigned 32-bit integer.
        timestamp: UInt32?

        /// The timeout duration (in seconds) for the LLM interaction. Defaults to 60 seconds.
        timeoutSeconds: Int? = 60
}

/// Retrieves the [ResourceChat] associated with the given [ID].
///
/// If the resource is not found, returns a new [ResourceChat] with default values.
///
/// [ID]: The ID of the resource to retrieve.
/// [ResourceChat]: The [ResourceChat] object associated with the resource ID.
function resource(ID: String): ResourceChat =
        if (resources.getOrNull(ID) != null) resources[ID] else new ResourceChat {
                prompt = ""
                response = ""
                JSONResponse = false
                JSONResponseKeys {}
        }

/// Retrieves the response text associated with the resource [ID].
///
/// [ID]: The ID of the resource to retrieve the response for.
/// [str]: The response text returned by the LLM model.
function response(ID: String): String = if (isBase64(resource(ID).response)) resource(ID).response.base64Decoded else resource(ID).response

/// Retrieves the prompt text associated with the resource [ID].
///
/// [ID]: The ID of the resource to retrieve the prompt for.
/// [str]: The prompt text sent to the LLM model.
function prompt(ID: String): String = if (isBase64(resource(ID).prompt)) resource(ID).prompt.base64Decoded else resource(ID).prompt

/// Retrieves whether the LLM's response for the resource [ID] is in JSON format.
///
/// [ID]: The ID of the resource to check for JSON response.
/// [bool]: True if the response is in JSON format, otherwise False.
function JSONResponse(ID: String): Boolean = if (isBase64(resource(ID).JSONResponse)) resource(ID).JSONResponse.base64Decoded else resource(ID).JSONResponse

/// Retrieves the JSON response keys for the resource [ID].
///
/// [ID]: The ID of the resource to retrieve the JSON response keys for.
/// [Listing<String>]: A listing of expected JSON keys in the response.
function JSONResponseKeys(ID: String): Listing<String> = if (isBase64(resource(ID).JSONResponseKeys)) resource(ID).JSONResponseKeys.base64Decoded else resource(ID).JSONResponseKeys

/// Retrieves the file path containing the LLM response associated with the specified resource [ID].
///
/// [ID]: The ID of the resource to retrieve the response for.
/// Returns the decoded content if the file is Base64-encoded; otherwise, returns the file content as-is.
function file(ID: String): String = if (isBase64(resource(ID).file)) resource(ID).file.base64Decoded else resource(ID).file
