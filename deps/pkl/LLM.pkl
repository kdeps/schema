@go.Package { name = "github.com/kdeps/schema/gen/llm" }

module org.kdeps.pkl.LLM

import "package://pkg.pkl-lang.org/pkl-go/pkl.golang@0.5.0#/go.pkl"

typealias LLMBackend = "ollama"|"api"

class LLMSettings {
  llmAPIKeys: LLMAPIKeys?
  llmBackend: LLMBackend = "ollama"
  llmModel: String = "llama3.1"
  modelFile: ModelFile?
}

class Parameter {
  mirostat: Int = 0
  mirostat_eta: Float = 0.1
  mirostat_tau: Float = 5.0
  num_ctx: Int = 2048
  repeat_last_n: Int = 64
  repeat_penalty: Float = 1.1
  temperature: Float = 0.8
  seed: Int = 0
  tfs_z: Float = 1.0
  num_predict: Int = 128
  top_k: Int = 40
  top_p: Float = 0.9
  min_p: Float = 0.0
}

class LLMAPIKeys {
  openai_api_key: String?
  mistral_api_key: String?
  huggingface_api_token: String?
  groq_api_key: String?
}

class ModelFile {
  hidden idStringRegex = Regex(#"(^\w+$)"#)

  hidden isValidModelId = (str) ->
  if (str.matches(idStringRegex))
    true
  else
    throw("Error: Invalid model name: The model name contains invalid characters. Please ensure it only includes alphanumeric characters (letters and numbers) and is not empty.")

  name: String(isValidModelId)
  from: String
  parameter: Parameter
  template: String = """
  {{ if .System }}<|start_header_id|>system<|end_header_id|>
  {{ .System }}<|eot_id|>{{ end }}{{ if .Prompt }}<|start_header_id|>user<|end_header_id|>
  {{ .Prompt }}<|eot_id|>{{ end }}<|start_header_id|>assistant<|end_header_id|>
  {{ .Response }}<|eot_id|>
  """
  stop: Listing<String> = new {
    "<|start_header_id|>"
    "<|end_header_id|>"
    "<|eot_id|>"
    "<|reserved_special_token"
  }

  hidden system: String?
  hidden adapter: String?
  hidden license: String?
  hidden message: Listing<String>?
}

class ResourceChat {
  hidden llmActionPrefixRegex = Regex(#"^(?i:(ENV|FILE):)(.+$)"#)

  hidden isValidLLMIOPrefix = (str) ->
  if (str.matches(llmActionPrefixRegex))
    true
  else
    throw("Error: Invalid configuration string: The LLM output string does not match any of the expected formats: ENV:, FILE:. Please ensure that the string starts with one of these prefixes.")

  prompt: String
  input: String(isValidLLMIOPrefix)?
  output: String(isValidLLMIOPrefix)
}

class ResourceChatSchema {
  hidden llmActionPrefixRegex = Regex(#"^(?i:(ENV|FILE):)(.+$)"#)

  hidden isValidLLMIOPrefix = (str) ->
  if (str.matches(llmActionPrefixRegex))
    true
  else
    throw("Error: Invalid configuration string: The LLM output string does not match any of the expected formats: ENV:, FILE:. Please ensure that the string starts with one of these prefixes.")

  prompt: String
  schema: String
  input: String(isValidLLMIOPrefix)?
  output: String(isValidLLMIOPrefix)
}
